from typing import List, Dict, Any, Optional, Union
import platform
import asyncpg
import asyncssh
from sshtunnel import SSHTunnelForwarder

from interfaces import IAsyncDatabaseService
from models import DatabaseConfig
from decorators import async_retry, log_execution, log_errors, measure_time
import logging

logger = logging.getLogger(__name__)


class AsyncPostgreSQLService(IAsyncDatabaseService):

    def __init__(self, config: DatabaseConfig):
        self.config = config
        self.pool: Optional[asyncpg.Pool] = None
        self.tunnel: Optional[Union[asyncssh.SSHClientConnection, SSHTunnelForwarder]] = None
        self.listener = None
        self.is_async_tunnel: bool = False
        self.local_port: Optional[int] = None

    async def __aenter__(self):
        await self.connect()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.disconnect()

    @log_execution()
    @async_retry(max_attempts=3, exceptions=(asyncpg.PostgresError,))
    async def connect(self) -> None:
        if self.config.ssh_config:
            await self._setup_ssh_tunnel()
            host = '127.0.0.1'
            port = self.local_port
        else:
            host = self.config.host
            port = self.config.port

        self.pool = await asyncpg.create_pool(
            host=host,
            port=port,
            database=self.config.name,
            user=self.config.user,
            password=self.config.password,
            min_size=2,
            max_size=10,
            command_timeout=60,
        )

        logger.info(f"Connected to database: {self.config.name} ({host}:{port}) [ASYNC POOL]")

    @log_errors()
    async def disconnect(self) -> None:
        if self.pool:
            await self.pool.close()
            logger.info(f"Disconnected from database: {self.config.name}")

        if self.listener:
            self.listener.close()
            await self.listener.wait_closed()

        if self.tunnel:
            if self.is_async_tunnel:
                self.tunnel.close()
                await self.tunnel.wait_closed()
                logger.info(f"Async SSH tunnel stopped for {self.config.name}")
            else:
                self.tunnel.stop()
                logger.info(f"Sync SSH tunnel stopped for {self.config.name}")

    async def _setup_ssh_tunnel(self) -> None:
        ssh_cfg = self.config.ssh_config

        if platform.system() == "Windows":
            logger.info(f"Detected Windows OS. Using synchronous SSH tunnel for {self.config.name}")

            self.tunnel = SSHTunnelForwarder(
                (ssh_cfg.host, ssh_cfg.port),
                ssh_username=ssh_cfg.user,
                ssh_password=ssh_cfg.password,
                remote_bind_address=(self.config.host, self.config.port),
            )
            self.tunnel.start()
            self.local_port = self.tunnel.local_bind_port
            self.is_async_tunnel = False

            logger.info(
                f"Sync SSH tunnel created for {self.config.name}. "
                f"Local port: {self.local_port}"
            )
        else:
            logger.info(f"Detected {platform.system()} OS. Using async SSH tunnel for {self.config.name}")

            self.tunnel = await asyncssh.connect(
                ssh_cfg.host,
                port=ssh_cfg.port,
                username=ssh_cfg.user,
                password=ssh_cfg.password,
                known_hosts=None,
            )

            self.listener = await self.tunnel.forward_local_port(
                '127.0.0.1',
                0,
                self.config.host,
                self.config.port
            )

            self.local_port = self.listener.get_port()
            self.is_async_tunnel = True

            logger.info(
                f"Async SSH tunnel created for {self.config.name}. "
                f"Local port: {self.local_port} [ASYNC]"
            )

    @measure_time(threshold_seconds=10.0)
    @log_errors()
    async def fetch_data(self) -> List[List[Any]]:
        if not self.pool:
            raise RuntimeError("Database not connected")

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(self.config.query)

            if not rows:
                return []

            columns = list(rows[0].keys())

            logger.info(f"Fetched {len(rows)} rows from {self.config.name} [ASYNC]")

            users_data = [list(dict(r).values()) for r in rows]

            user_ids = [row[0] for row in users_data if row and row[0] is not None]

            if not user_ids:
                logger.warning("No user IDs for funnel history query")
                return [columns] + users_data

            funnel_data = await self._fetch_funnel_data(user_ids)
            merged_data = self._merge_funnel_data(users_data, funnel_data)

            headers = columns + ['funnel_history', 'last_action_date', 'max_funnel_action']
            return [headers] + merged_data

    @async_retry(max_attempts=2, exceptions=(asyncpg.PostgresError,))
    async def execute_query(self, query: str, params: tuple = None) -> List[tuple]:
        if not self.pool:
            raise RuntimeError("Database not connected")

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, *(params or ()))
            return [tuple(r.values()) for r in rows]

    async def _fetch_funnel_data(self, user_ids: List[int]) -> Dict[int, Dict]:
        """
        üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ –¥–≤—É—Ö –æ—Ç–¥–µ–ª—å–Ω—ã—Ö
        
        –ë–´–õ–û (—Ç–≤–æ—è –≤–µ—Ä—Å–∏—è):
        - 2 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ 2 —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è—Ö
        - history_task: SELECT FROM funnel_history
        - state_task: SELECT FROM user_funnel
        - –í—Ä–µ–º—è: ~8-10 —Å–µ–∫—É–Ω–¥
        
        –°–¢–ê–õ–û:
        - 1 –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å CTE –∏ FULL OUTER JOIN
        - JSON aggregation –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
        - –í—Ä–µ–º—è: ~3-5 —Å–µ–∫—É–Ω–¥
        - –≠–ö–û–ù–û–ú–ò–Ø: ~5 —Å–µ–∫—É–Ω–¥ üöÄ
        
        Args:
            user_ids: –°–ø–∏—Å–æ–∫ Telegram ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–æ—Ä–æ–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        
        # üöÄ –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ô –ó–ê–ü–†–û–°: history + state –≤ –æ–¥–Ω–æ–º SQL
        query = """
        WITH history_agg AS (
            -- –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –≤ JSON –º–∞—Å—Å–∏–≤
            SELECT 
                user_id,
                json_agg(
                    json_build_object('label', label, 'datetime', datetime)
                    ORDER BY datetime
                ) as history,
                MAX(datetime) as last_action_date
            FROM funnel_history
            WHERE user_id = ANY($1::bigint[])
            GROUP BY user_id
        ),
        latest_state AS (
            -- –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–∞—Ç—É—Å
            SELECT DISTINCT ON (user_id) 
                user_id, 
                label as state
            FROM user_funnel
            WHERE user_id = ANY($1::bigint[])
            ORDER BY user_id, datetime DESC
        )
        -- –û–±—ä–µ–¥–∏–Ω—è–µ–º history –∏ state
        SELECT 
            COALESCE(h.user_id, s.user_id) as user_id,
            COALESCE(h.history, '[]'::json) as history,
            COALESCE(h.last_action_date::text, '') as last_action_date,
            COALESCE(s.state, '') as state
        FROM history_agg h
        FULL OUTER JOIN latest_state s ON h.user_id = s.user_id
        """
        
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(query, user_ids)
        
        funnel_data = {}
        
        for row in rows:
            user_id = row['user_id']
            
            # Parse JSON history
            import json
            history_json = row['history']
            if isinstance(history_json, str):
                history = json.loads(history_json)
            else:
                history = history_json if history_json else []
            
            funnel_data[user_id] = {
                'history': history,
                'last_action_date': row['last_action_date'] or '',
                'state': row['state'] or ''
            }
        
        logger.debug(f"Fetched funnel data for {len(funnel_data)} users in single query [OPTIMIZED]")
        
        return funnel_data

    def _merge_funnel_data(
        self,
        users_data: List[List[Any]],
        funnel_data: Dict[int, Dict]
    ) -> List[List[Any]]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–æ—Ä–æ–Ω–∫–∏
        
        Args:
            users_data: –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            funnel_data: –î–∞–Ω–Ω—ã–µ –≤–æ—Ä–æ–Ω–∫–∏ –∏–∑ _fetch_funnel_data
            
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏ –≤–æ—Ä–æ–Ω–∫–∏
        """
        merged_data = []

        for row in users_data:
            user_id = int(row[0])
            user_funnel = funnel_data.get(user_id, {
                'history': [],
                'last_action_date': '',
                'state': ''
            })

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤–æ—Ä–æ–Ω–∫–∏
            history_parts = [
                f"[{h['datetime']} - {h['label']}]"
                for h in user_funnel['history']
            ]
            history_str = "\n".join(history_parts) if history_parts else ""

            # –û–±—Ä–µ–∑–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ (Google Sheets –ª–∏–º–∏—Ç ~50k —Å–∏–º–≤–æ–ª–æ–≤)
            if len(history_str) > 40_000:
                if len(history_parts) > 200:
                    history_str = (
                        "\n".join(history_parts[:100]) +
                        f"\n[...{len(history_parts)-200} entries...]" +
                        "\n".join(history_parts[-100:])
                    )
                else:
                    history_str = history_str[:40_000] + "\n[TRUNCATED]"

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤–æ—Ä–æ–Ω–∫–∏ –∫ –¥–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            merged_row = row + [
                history_str,                        # funnel_history
                user_funnel['last_action_date'],    # last_action_date
                user_funnel['state']                # max_funnel_action
            ]
            merged_data.append(merged_row)

        return merged_data
